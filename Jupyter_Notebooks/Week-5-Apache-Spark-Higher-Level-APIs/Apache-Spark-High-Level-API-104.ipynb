{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use case - Spark DataFrame and SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/25 20:36:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init\n",
    "import getpass\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.sql.catalogImplementation\", \"hive\"). \\\n",
    "    config(\"spark.sql.warehouse.dir\",f\"/Users/{username}/Documents/data/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    master(\"local\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"inferSchema\", \"true\") \\\n",
    ".load(\"/Users/sugumarsrinivasan/Documents/data/orders_wh.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+------------+\n",
      "|order_id|         order_date|customer_id|order_status|\n",
      "+--------+-------------------+-----------+------------+\n",
      "|       1|2013-07-27 00:00:00|      30265|      CLOSED|\n",
      "|       2|2013-11-25 00:00:00|      20386|      CLOSED|\n",
      "|       3|2014-01-21 00:00:00|      15768|    COMPLETE|\n",
      "|       4|2014-07-04 00:00:00|      27181|  PROCESSING|\n",
      "|       5|2014-03-08 00:00:00|      12448|    COMPLETE|\n",
      "+--------+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.createOrReplaceTempView(\"orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Top 15 customers who placed the most number of orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|      42247|   11|\n",
      "|      30302|   10|\n",
      "|      48452|   10|\n",
      "|       5305|   10|\n",
      "|      44607|   10|\n",
      "|      31823|    9|\n",
      "|      39444|    9|\n",
      "|       4244|    9|\n",
      "|       9327|    9|\n",
      "|      27462|    9|\n",
      "|      34386|    9|\n",
      "|      14519|    9|\n",
      "|       8745|    9|\n",
      "|      22450|    9|\n",
      "|      28522|    9|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = orders_df.groupBy(\"customer_id\").count().sort(\"count\",ascending = False).limit(15)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|      42247|   11|\n",
      "|      30302|   10|\n",
      "|      48452|   10|\n",
      "|       5305|   10|\n",
      "|      44607|   10|\n",
      "|      31823|    9|\n",
      "|      39444|    9|\n",
      "|       4244|    9|\n",
      "|       9327|    9|\n",
      "|      27462|    9|\n",
      "|      34386|    9|\n",
      "|      14519|    9|\n",
      "|       8745|    9|\n",
      "|      22450|    9|\n",
      "|      28522|    9|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"select customer_id, count(*) as count from orders group by customer_id order by count desc limit 15\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find the number of orders under each order status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|   order_status|count|\n",
      "+---------------+-----+\n",
      "|PENDING_PAYMENT|25099|\n",
      "|       COMPLETE|24837|\n",
      "|     PROCESSING|25048|\n",
      "|         CLOSED|25016|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = orders_df.groupBy(\"order_status\").count()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|   order_status|count|\n",
      "+---------------+-----+\n",
      "|PENDING_PAYMENT|25099|\n",
      "|       COMPLETE|24837|\n",
      "|     PROCESSING|25048|\n",
      "|         CLOSED|25016|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"select order_status, count(order_id) as count from orders group by order_status\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Number of Active customers(who placed atleast one order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43241\n"
     ]
    }
   ],
   "source": [
    "result = orders_df.select(\"customer_id\").distinct().count()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|active_customers|\n",
      "+----------------+\n",
      "|           43241|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct(customer_id)) as active_customers from orders\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. customer with most number of closed orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       9192|    6|\n",
      "|       9207|    5|\n",
      "|      42096|    5|\n",
      "|      21078|    5|\n",
      "|        624|    5|\n",
      "|       4086|    5|\n",
      "|      43851|    5|\n",
      "|      35155|    5|\n",
      "|      38525|    5|\n",
      "|      33360|    5|\n",
      "|      18797|    4|\n",
      "|      38911|    4|\n",
      "|      46049|    4|\n",
      "|      48102|    4|\n",
      "|      13351|    4|\n",
      "|       8007|    4|\n",
      "|      29566|    4|\n",
      "|       8449|    4|\n",
      "|      42119|    4|\n",
      "|      10112|    4|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = orders_df.filter(\"order_status = 'CLOSED'\").groupBy(\"customer_id\").count().sort(\"count\", ascending = False)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "|       9192|    6|\n",
      "|       9207|    5|\n",
      "|      42096|    5|\n",
      "|      21078|    5|\n",
      "|        624|    5|\n",
      "|       4086|    5|\n",
      "|      43851|    5|\n",
      "|      35155|    5|\n",
      "|      38525|    5|\n",
      "|      33360|    5|\n",
      "|      18797|    4|\n",
      "|      38911|    4|\n",
      "|      46049|    4|\n",
      "|      48102|    4|\n",
      "|      13351|    4|\n",
      "|       8007|    4|\n",
      "|      29566|    4|\n",
      "|       8449|    4|\n",
      "|      42119|    4|\n",
      "|      10112|    4|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"select customer_id, count(*) as count from orders where order_status = 'CLOSED' group by customer_id order by count desc\")\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
