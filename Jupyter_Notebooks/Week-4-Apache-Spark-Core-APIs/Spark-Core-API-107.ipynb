{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repartition Vs Coalesce:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Feature**                 | **repartition()**                                  | **coalesce()**                                      |\n",
    "|-----------------------------|---------------------------------------------------|-----------------------------------------------------|\n",
    "| **Functionality**            | Reshuffles the data and can increase or decrease partitions. | Reduces the number of partitions by merging adjacent partitions. |\n",
    "| **Number of Partitions**     | Can increase or decrease the number of partitions. | Only decreases the number of partitions. It cannot increase partitions. |\n",
    "| **Shuffling**                | Involves a full shuffle, which is costly and may be slow. | Involves less shuffle (only adjacent partitions), making it more efficient. |\n",
    "| **Use Case**                 | Used when you need to increase the number of partitions or when a shuffle is required. | Best for reducing the number of partitions (e.g., before writing to disk). |\n",
    "| **Performance**              | Can be slower due to the full shuffle.           | More efficient since it avoids full shuffle and only merges adjacent partitions. |\n",
    "| **Typical Use Case**         | Scaling up data processing (e.g., increasing parallelism). | Optimizing the number of partitions when you want to reduce overhead (e.g., before saving data). |\n",
    "| **Partition Splitting**      | Can split a large partition into smaller ones.    | Cannot split partitions; only merges them. |\n",
    "| **Internal Mechanism**       | Triggers a full shuffle across all partitions.    | Merges adjacent partitions without a full shuffle. |\n",
    "| **API**                      | `DataFrame.repartition(numPartitions)`           | `DataFrame.coalesce(numPartitions)`                 |\n",
    "| **Example**                  | `df.repartition(10)`                             | `df.coalesce(2)`                                    |\n",
    "| **Performance Consideration**| Costly if the number of partitions is reduced significantly. | More efficient for reducing partitions but should not be used for increasing partitions. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Differences:**\n",
    "\n",
    "**Repartition:**\n",
    "-   Involves a full shuffle of the data.\n",
    "-   Useful for increasing the number of partitions.\n",
    "-   More computationally expensive.\n",
    "\n",
    "**Coalesce:**\n",
    "-   Involves merging adjacent partitions without a full shuffle.\n",
    "-   Primarily used for decreasing the number of partitions.\n",
    "-   More efficient when reducing the number of partitions, especially when the number is reduced by a large factor (e.g., from hundreds to a few)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/23 09:21:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySparkExample\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples for repartition:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_base = spark.sparkContext.textFile(\"/Users/sugumarsrinivasan/Documents/data/sample_orders_1GB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num of Partitions before repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_base.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num of Partitions after increasing the partitions using repartition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartitioned_orders_base = orders_base.repartition(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repartitioned_orders_base.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "repartitioned_orders_base.saveAsTextFile(\"/Users/sugumarsrinivasan/Documents/data/repartition_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of partitions after decreasing the partitions using repartition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_orders_base = repartitioned_orders_base.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_orders_base.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image](./screenshots/spark-repartition-job.png)\n",
    "![Local Image](./screenshots/spark-repartition-stage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples for Coaleasce:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num of partitions before reducing the partition count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_base.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_orders_rdd = orders_base.coalesce(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num of Partitions after decrease the partitions using coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_orders_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_orders_rdd.saveAsTextFile(\"/Users/sugumarsrinivasan/Documents/data/coalesce_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local Image](./screenshots/spark-coalesce-job.png)\n",
    "![Local Image](./screenshots/spark-coalesce-stage.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
