{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark Session:**\n",
    "\n",
    "In PySpark, a SparkSession is the entry point for working with Spark functionality. It provides a unified interface to interact with various Spark components and APIs, such as Spark SQL, DataFrame API, Streaming, and more. SparkSession is essential for interacting with Spark and for initiating Spark-related operations.\n",
    "\n",
    "**Overview of SparkSession**\n",
    "\n",
    "**A SparkSession encapsulates the following features:**\n",
    "\n",
    "-   **SparkContext:** A SparkContext is the underlying object that connects to a Spark cluster. The SparkSession implicitly creates a SparkContext when initialized, which can be accessed via spark.sparkContext.\n",
    "\n",
    "-   **SQLContext:** For interacting with Spark SQL. It’s implicitly available in the SparkSession and allows running SQL queries on DataFrames.\n",
    "\n",
    "-   **HiveContext (optional):** For working with Apache Hive (if Spark is configured with Hive support).\n",
    "\n",
    "-   **Configuration:** Used to configure the Spark session, including setting Spark properties (e.g., memory, parallelism).\n",
    "\n",
    "Starting from Spark 2.0, SparkSession consolidates these components and serves as a single entry point for all functionalities in Spark.\n",
    "\n",
    "**Creating a SparkSession**\n",
    "\n",
    "create a SparkSession, use the SparkSession.builder API, typically written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init\n",
    "import getpass\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName(\"Spark Session Demo\"). \\\n",
    "    config(\"spark.sql.catalogImplementation\", \"hive\"). \\\n",
    "    config(\"spark.sql.warehouse.dir\",f\"/Users/{username}/Documents/data/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    master(\"local[*]\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   **appName(\"ExampleApp\"):** This sets the application name to be shown in the Spark UI.\n",
    "\n",
    "-   **config(...):** Allows setting specific configurations for Spark (e.g., memory allocation, number of partitions, etc.).\n",
    "\n",
    "-   **enableHiveSupport():** If you need to use Hive, this will enable support for the Hive context, allowing you to run Hive queries.\n",
    "\n",
    "-    **local[*]:** indicates that Spark should run locally on your machine and use all available CPU cores.\n",
    "\n",
    "-   **getOrCreate():** This either retrieves the existing SparkSession or creates a new one if it doesn’t exist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes**\n",
    "\n",
    "**Single SparkSession:** It's best practice to use a single SparkSession for the lifetime of your application. Creating multiple sessions may lead to issues, and managing multiple sessions can become cumbersome.\n",
    "\n",
    "**Shared Context:** SparkContext and SparkSession are closely related. A SparkSession automatically creates a SparkContext, but the reverse is not true (i.e., you cannot directly create a SparkContext without a SparkSession in PySpark).\n",
    "\n",
    "**Lazy Evaluation:** Operations on DataFrames and RDDs are lazily evaluated. That means transformations (like filter, select, etc.) are not executed immediately but only when an action (like show, collect, etc.) is triggered.\n",
    "\n",
    "**Performance:** Spark sessions are optimized for performance through Catalyst optimization (query planning) and Tungsten execution (physical execution). By using DataFrames and SQL, you automatically benefit from these optimizations.\n",
    "\n",
    "**Access to Spark UI:** When running a Spark job, you can access the Spark UI by navigating to the web URL (usually localhost:4040 for local mode) to view stages, tasks, and more.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "-   SparkSession is the central entry point for all Spark functionality in PySpark.\n",
    "\n",
    "-   It manages the SparkContext, allows reading data from various sources, and enables SQL queries on DataFrames.\n",
    "\n",
    "-   SparkSession integrates features of SQLContext, HiveContext, and SparkContext in one unified API.\n",
    "\n",
    "This unified approach makes working with PySpark more streamlined, as you only need to interact with one object to access all Spark capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PySpark Deployment Modes: Client Mode vs Cluster Mode Explained**\n",
    "\n",
    "In PySpark, \"client mode\" and \"cluster mode\" refer to two different deployment modes for running Spark applications. These modes define where the Spark driver (the process that controls the execution of your Spark job) runs, as well as how resources are allocated. The key difference lies in where the Spark driver runs and how Spark jobs are scheduled and executed.\n",
    "\n",
    "**1. Client Mode:**\n",
    "\n",
    "In client mode, the Spark driver runs on the machine where the Spark application is submitted (typically your local machine or the machine from which you are running the job). The executors (the worker processes that perform the actual computation) still run on the cluster.\n",
    "\n",
    "-   **Where the Driver Runs:** The driver runs on the local machine or client machine where the Spark job was launched.\n",
    "\n",
    "-   **Where the Executors Run:** The executors run on the cluster (worker nodes), distributed across the resources managed by Spark.\n",
    "\n",
    "-   **Usage:** This mode is typically used in interactive or local testing scenarios. It is common when you are submitting a Spark job from a local machine, where you want the driver to be located on that same machine.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "-   Simpler to debug and interact with because you have direct access to the driver's console and logs.\n",
    "\n",
    "-   More useful for jobs where the driver performs some form of interactive work or where you need to monitor the job closely.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "-   The client machine may not have sufficient resources to handle large jobs, leading to potential performance bottlenecks or failures if the job is large or resource-intensive.\n",
    "\n",
    "-   Communication between the driver and executors can be slower, as the driver is not co-located with the cluster.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "spark-submit --master yarn --deploy-mode client your_spark_application.py\n",
    "```\n",
    "\n",
    "**2. Cluster Mode:**\n",
    "\n",
    "In cluster mode, both the driver and the executors are launched on the cluster. The driver runs as a distributed application on one of the worker nodes within the cluster, and the Spark job is fully managed by the cluster's resource manager (e.g., YARN, Mesos, Kubernetes).\n",
    "\n",
    "-   **Where the Driver Runs:** The driver is launched on a worker node within the cluster.\n",
    "\n",
    "-   **Where the Executors Run:** The executors also run on the worker nodes, just like in client mode.\n",
    "\n",
    "-   **Usage:** This mode is typically used for production jobs, where performance and resource management are critical. It is often used in a \n",
    "multi-node cluster where you don't need to interact with the driver directly but rather rely on the cluster to manage all aspects of the job.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "-   Better suited for large jobs that require significant resources, as both the driver and executors are managed by the cluster's resource manager.\n",
    "\n",
    "-   More fault-tolerant: The driver is hosted on the cluster, so it is less likely to fail due to client machine issues.\n",
    "\n",
    "-   More scalable, as the resources can be dynamically allocated based on the workload.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "-   More complex to debug since the driver runs on the cluster, and you don’t have easy access to the local environment for debugging.\n",
    "\n",
    "-   Logs and output may be less immediately accessible compared to client mode, depending on the cluster's setup.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "spark-submit --master yarn --deploy-mode cluster your_spark_application.py\n",
    "```\n",
    "\n",
    "| **Aspect**                | **Client Mode**                         | **Cluster Mode**                         |\n",
    "|---------------------------|-----------------------------------------|------------------------------------------|\n",
    "| **Where the Driver Runs**  | Local machine (client)                  | On a worker node in the cluster          |\n",
    "| **Where the Executors Run**| On the cluster                          | On the cluster                           |\n",
    "| **Resource Allocation**    | Managed by the local machine            | Managed by the cluster's resource manager (e.g., YARN, Kubernetes) |\n",
    "| **Use Case**               | Local testing, small-scale jobs         | Large-scale, production jobs            |\n",
    "| **Fault Tolerance**        | Depends on the local machine            | More fault-tolerant (driver runs on the cluster) |\n",
    "| **Scalability**            | Limited by the resources of the local machine | More scalable, resources allocated dynamically by the cluster |\n",
    "| **Driver Accessibility**   | Easier to debug (direct access to driver logs) | Harder to debug (driver runs on cluster, may need remote access for logs) |\n",
    "| **Communication Overhead** | Higher, as the driver and executors are on separate machines | Lower, as the driver and executors run on the cluster |\n",
    "| **Performance**            | Can be slower due to network communication overhead | Optimized for distributed computation and better performance |\n",
    "| **Ideal for**              | Development, testing, interactive work  | Production, large-scale data processing |\n",
    "\n",
    "**When to Use Each Mode:**\n",
    "\n",
    "-   **Client Mode:** Use when you need to run small Spark jobs from a local machine, need quick feedback, or are working in an interactive mode (e.g., a Jupyter notebook). It’s also suitable for development and testing, where you want to monitor the job directly from the client machine.\n",
    "\n",
    "-   **Cluster Mode:** Use for production jobs or large-scale data processing tasks where the job requires significant resources and performance. It’s ideal when you want Spark to fully manage the execution, including resource allocation, fault tolerance, and distributed execution across the cluster.\n",
    "\n",
    "In summary, client mode is easier for development and debugging, whereas cluster mode is more suited for production-scale jobs with better fault tolerance and resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Roles of Driver and Executor in PySpark**\n",
    "\n",
    "In PySpark (and Apache Spark in general), Driver and Executor are two key components that handle the execution of Spark jobs, but they have very distinct roles in the architecture.\n",
    "\n",
    "**1. Driver:**\n",
    "\n",
    "The Driver is the central control unit of a Spark application. It is responsible for:\n",
    "\n",
    "-   **Starting the Spark Context:** The driver creates and maintains the SparkContext (or SparkSession in higher-level APIs like PySpark) which coordinates the entire Spark application.\n",
    "\n",
    "-   **Task Scheduling:** The driver schedules tasks and divides the work into smaller units (called stages and tasks), which it then sends to executors for execution.\n",
    "\n",
    "-   **Job Execution Coordination:** The driver controls the overall flow of the job. It:\n",
    "\n",
    "    -   Divides the job into multiple stages.\n",
    "\n",
    "    -   Sends tasks to executors.\n",
    "\n",
    "    -   Collects and combines the results from all executors.\n",
    "\n",
    "-   **Fault Tolerance:** The driver handles task retries if an executor fails or a task needs to be re-executed.\n",
    "\n",
    "-   **Result Collection:** Once the computation is done, the driver gathers the results from the executors and typically returns the final result to the user.\n",
    "\n",
    "In a PySpark context, the driver runs the Python code that is written by the user (e.g., scripts, transformations, actions). This is where your Python functions (like .map(), .filter(), .reduce()) are executed.\n",
    "\n",
    "**2. Executor:**\n",
    "\n",
    "An Executor is a worker node in the cluster that runs the actual computations and stores data for the Spark application. Its key responsibilities include:\n",
    "\n",
    "-   **Executing Tasks:** Executors perform the work that the driver schedules. When the driver sends tasks, the executor runs them and performs the operations on the data.\n",
    "\n",
    "-   **Storing Data:** Executors store both intermediate and final data. They hold the data that is cached or persisted and also keep RDDs (Resilient Distributed Datasets) and DataFrames that are being processed.\n",
    "\n",
    "-   **Handling Shuffles:** Executors handle data shuffling (data transfer between nodes) when needed (e.g., during a groupBy or join operation).\n",
    "\n",
    "-   **Reporting Status:** Executors report the progress of tasks back to the driver, including whether tasks are successful or if there were failures.\n",
    "\n",
    "Each Spark worker node runs one or more executors, depending on the available resources (e.g., CPU cores, memory).\n",
    "\n",
    "**Key Differences**\n",
    "\n",
    "| Feature                    | Driver                                    | Executor                                        |\n",
    "|----------------------------|-------------------------------------------|-------------------------------------------------|\n",
    "| **Role**                    | Controls and coordinates the job         | Performs computations and stores data           |\n",
    "| **Location**                | Runs on the machine where the Spark job is submitted (usually a local or master node) | Runs on worker nodes in the Spark cluster      |\n",
    "| **Task Scheduling**         | Divides the job into tasks and schedules them | Executes the tasks assigned by the driver       |\n",
    "| **Fault Tolerance**         | Handles failure by retrying tasks or resubmitting jobs | If an executor fails, tasks assigned to it are rescheduled on other executors |\n",
    "| **Memory**                  | Holds the driver program's variables (e.g., Python variables, configurations) | Holds RDD/DataFrame partitions and intermediate results |\n",
    "| **Data Storage**            | Does not store data, just coordinates job execution | Stores intermediate and final results, and can cache/persist data |\n",
    "| **Running Code**            | Runs user code, orchestrates transformations/actions | Executes the code that was assigned to it (like running a map operation on an RDD) |\n",
    "\n",
    "**Example Workflow:**\n",
    "\n",
    "-   You submit a PySpark job, which starts a driver.\n",
    "\n",
    "-   The driver breaks the job into smaller tasks and assigns them to executors.\n",
    "\n",
    "-   Executors process the tasks in parallel and return results to the driver.\n",
    "\n",
    "-   The driver collects the results and either returns them to the user or writes them to external storage (e.g., HDFS, S3, etc.).\n",
    "\n",
    "**Summary:**\n",
    "\n",
    "-   **Driver** = The master of the Spark application: it schedules tasks and coordinates execution.\n",
    "\n",
    "-   **Executor** = The workers: they execute the tasks and store data.\n",
    "\n",
    "Understanding this distinction is critical for optimizing performance, as tuning resources and the number of executors, along with understanding the role of the driver in scheduling tasks, can greatly impact the efficiency of a Spark job.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark-env)",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
